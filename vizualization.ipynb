{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0292e14",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFoundError",
     "evalue": "b'./home/hitesh/Documents/Project/semantic_segmentation/runs/events.out.tfevents.1767285339.hitesh-ASUS-TUF-Gaming-A15-FA506NCR-FA566NCR.24583.0' does not point to valid Events file",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 28\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m scalar found. Available scalars: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mea\u001b[38;5;241m.\u001b[39mTags()[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscalars\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# Example usage:\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# plot_loss_from_tensorboard('runs/experiment_1')\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m \u001b[43mplot_loss_from_tensorboard\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./home/hitesh/Documents/Project/semantic_segmentation/runs/events.out.tfevents.1767285339.hitesh-ASUS-TUF-Gaming-A15-FA506NCR-FA566NCR.24583.0\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[2], line 7\u001b[0m, in \u001b[0;36mplot_loss_from_tensorboard\u001b[0;34m(log_path)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mplot_loss_from_tensorboard\u001b[39m(log_path):\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;66;03m# Initialize EventAccumulator with the path to the log directory\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m     ea \u001b[38;5;241m=\u001b[39m \u001b[43mEventAccumulator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlog_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m     ea\u001b[38;5;241m.\u001b[39mReload()\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;66;03m# Check if 'loss' exists in the scalars\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/semantic/lib/python3.9/site-packages/tensorboard/backend/event_processing/event_accumulator.py:312\u001b[0m, in \u001b[0;36mEventAccumulator.__init__\u001b[0;34m(self, path, size_guidance, compression_bps, purge_orphaned_data)\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generator_mutex \u001b[38;5;241m=\u001b[39m threading\u001b[38;5;241m.\u001b[39mLock()\n\u001b[1;32m    311\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpath \u001b[38;5;241m=\u001b[39m path\n\u001b[0;32m--> 312\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generator \u001b[38;5;241m=\u001b[39m \u001b[43m_GeneratorFromPath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compression_bps \u001b[38;5;241m=\u001b[39m compression_bps\n\u001b[1;32m    315\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpurge_orphaned_data \u001b[38;5;241m=\u001b[39m purge_orphaned_data\n",
      "File \u001b[0;32m~/anaconda3/envs/semantic/lib/python3.9/site-packages/tensorboard/backend/event_processing/event_accumulator.py:945\u001b[0m, in \u001b[0;36m_GeneratorFromPath\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    943\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpath must be a valid string\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    944\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m io_wrapper\u001b[38;5;241m.\u001b[39mIsSummaryEventsFile(path):\n\u001b[0;32m--> 945\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mevent_file_loader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLegacyEventFileLoader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    946\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    947\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m directory_watcher\u001b[38;5;241m.\u001b[39mDirectoryWatcher(\n\u001b[1;32m    948\u001b[0m         path,\n\u001b[1;32m    949\u001b[0m         event_file_loader\u001b[38;5;241m.\u001b[39mLegacyEventFileLoader,\n\u001b[1;32m    950\u001b[0m         io_wrapper\u001b[38;5;241m.\u001b[39mIsSummaryEventsFile,\n\u001b[1;32m    951\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/semantic/lib/python3.9/site-packages/tensorboard/backend/event_processing/event_file_loader.py:136\u001b[0m, in \u001b[0;36mRawEventFileLoader.__init__\u001b[0;34m(self, file_path, detect_file_replacement)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_detect_file_replacement \u001b[38;5;241m=\u001b[39m detect_file_replacement\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_file_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 136\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator \u001b[38;5;241m=\u001b[39m \u001b[43m_make_tf_record_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_file_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_detect_file_replacement \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreopen\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    139\u001b[0m ):\n\u001b[1;32m    140\u001b[0m     logger\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[1;32m    141\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile replacement detection requested, but not enabled because \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    142\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTF record iterator impl does not support reopening. This \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    143\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunctionality requires TensorFlow 2.9+\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    144\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/semantic/lib/python3.9/site-packages/tensorboard/backend/event_processing/event_file_loader.py:59\u001b[0m, in \u001b[0;36m_make_tf_record_iterator\u001b[0;34m(file_path)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tf\u001b[38;5;241m.\u001b[39m__version__ \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstub\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;66;03m# TODO(#1711): Reshape stub implementation to fit tf_record_iterator API\u001b[39;00m\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;66;03m# rather than needlessly emulating the old PyRecordReader_New API.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m     logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOpening a stub record reader pointing at \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, file_path)\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_PyRecordReaderIterator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpywrap_tensorflow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPyRecordReader_New\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile_path\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;66;03m# If PyRecordReader exists, use it, otherwise use tf_record_iterator().\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;66;03m# Check old first, then new, since tf_record_iterator existed previously but\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;66;03m# only gained the semantics we need at the time PyRecordReader was removed.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;66;03m# support for TF 2.1 and prior, and find a non-deprecated replacement for\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;66;03m# tf.compat.v1.io.tf_record_iterator.\u001b[39;00m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/semantic/lib/python3.9/site-packages/tensorboard/backend/event_processing/event_file_loader.py:96\u001b[0m, in \u001b[0;36m_PyRecordReaderIterator.__init__\u001b[0;34m(self, py_record_reader_new, file_path)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Constructs a _PyRecordReaderIterator for the given file path.\u001b[39;00m\n\u001b[1;32m     90\u001b[0m \n\u001b[1;32m     91\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;124;03m  py_record_reader_new: pywrap_tensorflow.PyRecordReader_New\u001b[39;00m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;124;03m  file_path: file path of the tfrecord file to read\u001b[39;00m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mcompat\u001b[38;5;241m.\u001b[39mv1\u001b[38;5;241m.\u001b[39merrors\u001b[38;5;241m.\u001b[39mraise_exception_on_not_ok_status() \u001b[38;5;28;01mas\u001b[39;00m status:\n\u001b[0;32m---> 96\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader \u001b[38;5;241m=\u001b[39m \u001b[43mpy_record_reader_new\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstatus\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader:\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(\n\u001b[1;32m    101\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to open a record reader pointing to \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m file_path\n\u001b[1;32m    102\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/semantic/lib/python3.9/site-packages/tensorboard/compat/tensorflow_stub/pywrap_tensorflow.py:177\u001b[0m, in \u001b[0;36mPyRecordReader_New.__init__\u001b[0;34m(self, filename, start_offset, compression_type, status)\u001b[0m\n\u001b[1;32m    173\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mNotFoundError(\n\u001b[1;32m    174\u001b[0m         \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo filename provided, cannot read Events\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    175\u001b[0m     )\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m gfile\u001b[38;5;241m.\u001b[39mexists(filename):\n\u001b[0;32m--> 177\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mNotFoundError(\n\u001b[1;32m    178\u001b[0m         \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    179\u001b[0m         \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    180\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m does not point to valid Events file\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(filename),\n\u001b[1;32m    181\u001b[0m     )\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m start_offset:\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mUnimplementedError(\n\u001b[1;32m    184\u001b[0m         \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstart offset not supported by compat reader\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    185\u001b[0m     )\n",
      "\u001b[0;31mNotFoundError\u001b[0m: b'./home/hitesh/Documents/Project/semantic_segmentation/runs/events.out.tfevents.1767285339.hitesh-ASUS-TUF-Gaming-A15-FA506NCR-FA566NCR.24583.0' does not point to valid Events file"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from tensorboard.backend.event_processing.event_accumulator import EventAccumulator\n",
    "\n",
    "def plot_loss_from_tensorboard(log_path):\n",
    "    # Initialize EventAccumulator with the path to the log directory\n",
    "    ea = EventAccumulator(log_path)\n",
    "    ea.Reload()\n",
    "\n",
    "    # Check if 'loss' exists in the scalars\n",
    "    if 'loss' in ea.Tags()['scalars']:\n",
    "        events = ea.Scalars('loss')\n",
    "        df = pd.DataFrame([(e.step, e.value) for e in events], columns=['epoch', 'loss'])\n",
    "\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(df['epoch'], df['loss'], label='Loss')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.title('Training Loss vs Epochs')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(f\"No 'loss' scalar found. Available scalars: {ea.Tags()['scalars']}\")\n",
    "\n",
    "# Example usage:\n",
    "# plot_loss_from_tensorboard('runs/experiment_1')\n",
    "plot_loss_from_tensorboard('./runs/events.out.tfevents.1767285339.hitesh-ASUS-TUF-Gaming-A15-FA506NCR-FA566NCR.24583.0')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "semantic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.25"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
